{
  "hash": "ca6e1287bf38c99a177fb81ac6fa2647",
  "result": {
    "markdown": "# Bayesian Thinking and Everyday Reasoning\n\n\n::: {.cell}\n\n:::\n\n\nBayesian reasoning is the formal process that we use to update our\nbeliefs about the world once we've observed some data.\n\n## Reasoning About Strange Experiences\n\n::: callout-note\nWill Kurt show with an UFO example how Bayesian thinking about beliefs\nand their updates when new data come is very natural and a common sense\nprocedure. This is an interesting approach I haven't thought before,\nbecause many Bayesian introductions are not only very complex but\ndevelops formulae that we are not using in the everyday world.\n:::\n\nBayesian reasoning procedure:\n\n1.  Observe data\n2.  Build a hypothesis\n3.  Update your beliefs based on new data\n\n### Observing Data\n\n$$P(\\text{bright light outside window}, \\text{saucer-shaped object in sky}) = \\text{very low}$$\nYou would read this equation as: \"The probability of observing bright\nlights outside the window and a saucer-shaped object in the sky is very\nlow.\" In probability theory, we use a comma to separate events when\nwe're looking at the combined probability of multiple events.\n\n### Holding Prior Beliefs and Conditioning Probabilities\n\n$$\n\\begin{align*}\nP(\\text{bright light outside window},\\\\ \n\\text{saucer-shaped object in sky} \\mid \\text{eperience on Earth}) = \\text{very low}\n\\end{align*}\n$$ {#eq-cond-prob} We would read this equation as: \"The probability of\nobserving bright lights and a saucer-shaped object in the sky, *given*\nour experience on Earth, is very low.\"\n\nThe probability outcome is called a\n<a class='glossary' title='In probability theory, conditional probability is a measure of the probability of an event occurring, given that another event (by assumption, presumption, assertion or evidence) has already occurred. Wikipedia. The mathematical notation uses the pipe symbol (’|’) for “conditional on” or “given that”.'>conditional probability</a> because we are conditioning the\nprobability of one event occurring on the existence of something else.\n\n**Shorter variable names for events and conditions**:\n\n-   D: all of our data\n-   X: prior belief\n\nLet\n$D = \\text{bright light outside window}, \\text{saucer-shaped object in sky}$\nand $X = \\text{experience on Earth}$ then we can wrote @eq-cond-prob as\n$P(D \\mid X) = \\text{very low})$.\n\n### Conditioning on Multiple Beliefs\n\n$$\n\\begin{align*}\nP(\\text{bright light outside window},\\\\ \n\\text{saucer-shaped object in sky} \\mid \\\\\n\\text{July 4th, eperience on Earth}) = \\text{low}\n\\end{align*}\n$$ {#eq-cond-prob-mult-beliefs} Taking both these experiences into\naccount, our conditional probability changed from \"very low\" to \"low.\"\n\n### Assuming Prior Beliefs in Practice\n\nIn order to explain what you saw, you need to form some kind of\n*hypothesis*---a model about how the world works that makes a\nprediction. All of our basic beliefs about the world are hypotheses.\n\n-   If you believe the Earth rotates, you predict the sun will rise and\n    set at certain times.\n-   If you believe that your favorite baseball team is the best, you\n    predict they will win more than the other teams.\n-   A scientist may hypothesize that a certain treatment will slow the\n    growth of cancer.\n-   A quantitative analyst in finance may have a model of how the market\n    will behave.\n\n$$H_{1} = \\text{A UFO is in my backyard!}$$\n\nBut what is this hypothesis predicting? We might ask, \"If there was a\nUFO in your back yard, what would you expect to see?\" And you might\nanswer, \"Bright lights and a saucer-shaped object.\" Formally we write\nthis as:\n\n$$\nP(D \\mid H_{1}, X) >> P(D \\mid X)\n$$\n\nThis equation says: \"The probability of seeing bright lights and a\nsaucer-shaped object in the sky, given my belief that this is a UFO and\nmy prior experience, is much higher \\[indicated by the double\ngreater-than sign \\>\\>\\] than just seeing bright lights and a\nsaucer-shaped object in the sky without explanation.\"\n\n### Spotting Hypotheses in Everyday Speech\n\n-   Saying something is \"surprising,\" for example, might be the same as\n    saying it has low-probability data based on our prior experiences.\n-   Saying something \"makes sense\" might indicate we have\n    high-probability data based on our prior experiences.\n\n## Gathering More Evidence and Updating Your Beliefs\n\nTo collect more data, we need to make more observations. In our\nscenario, you look out your window: With new evidence, you realize it\nlooks more like someone is shooting a movie nearby.\n\n**Bayesian analysis process**\n\n1.  You started with your initial hypothesis:\n    $H_{1} = \\text{A UFO is in my backyard!}$.\n2.  In isolation, this hypothesis, given your experience, is extremely\n    unlikely: $P(H_{1} \\mid X) = \\text{very, very low}$\n3.  With new data you are going to update your belief:\n    $H_{2} = \\text{A film is being made}$.\n4.  In isolation, the probability of this hypothesis is also intuitively\n    very low: $P(H_{1} \\mid X) = \\text{very low}$\n5.  You updated your prior belief from \"very, very low\" to \"very low\".\n\n## Comparing Hypotheses\n\nWith new data you have formed an *alternate hypothesis*. Let's break\nthis process down into Bayesian reasoning. Your first hypothesis,\n$H_{1}$, gave you a way to explain your data and end your confusion, but\nwith your additional observations $H_{1}$ no longer explains the data\nwell:\n\nYou started with\n\n$$P(D \\mid H_{1}, X) = \\text{very, very low}$$ and updated our belief\nwith\n\n$$P(D_{updated} \\mid H_{2}, X) >> P(D \\mid H_{1}, X)$$ We say that one\nbelief is more accurate than another because it provides a better\nexplanation of the world we observe. Mathematically, we express this\nidea as the ratio of the two probabilities:\n\n$$\\frac{P(D_{updated} \\mid H_{2}, X)}{P(D \\mid H_{1}, X)}$$\n\nWhen this ratio is a large number, say 1,000, it means \"$H_{2}$ explains\nthe data 1,000 times better than $H_{1}$.\"\n\n## Data Informs Belief; Belief Should Not Inform Data\n\nOne final point worth stressing is that the only absolute in all these\nexamples is your data. Your hypotheses change, and your experience in\nthe world, $X$, may be different from someone else's, but the data, $D$,\nis shared by all.\n\n**Case 1** (used throughout this chapter):\n\n$$P(D \\mid H, X)$$ {#eq-data-changing-belief} \"How well do my beliefs\nexplain what I observe?\"\n\n**Case 2** (used often in everyday thinking)\n\n$$P(H \\mid D, X)$$ {#eq-ensuring-data-supports-belief}\n\nIn the first case, we change our beliefs according to data we gather and\nobservations we make about the world that describe it better. In the\nsecond case, we gather data to support our existing beliefs. Bayesian\nthinking is about changing your mind and updating how you understand the\nworld. The data we observe is all that is real, so our beliefs\nultimately need to shift until they align with the data.\n\n## Wrapping Up\n\n::: callout-important\nYou should be far more concerned with data changing your beliefs\n$P(D \\mid H)$ (@eq-data-changing-belief) than with ensuring data\nsupports your beliefs, $P(H \\mid D)$\n(@eq-ensuring-data-supports-belief).\n:::\n\n## Exercises\n\nTry answering the following questions to see how well you understand\nBayesian reasoning. The solutions can be found at [No Starch\nPress](https://nostarch.com/download/resources/Bayes_exercise_solutions_new.pdf){target=\"_blank\"}\n(PDF).\n\n::: {#exr-01-1}\nRewrite the following statements as equations using the mathematical\nnotation you learned in this chapter:\n\n-   The probability of rain is low: $P(rain) = low$\n-   The probability of rain given that it is cloudy is high:\n    $P(rain \\mid cloudy) = high$\n-   The probability of you having an umbrella given it is raining is\n    much greater than the probability of you having an umbrella in\n    general:\n    $P(\\text{I have umbrella} \\mid \\text{raining}) >> P(\\text{I have umbrella})$\n:::\n\n------------------------------------------------------------------------\n\n::: {#exr-01-2}\nOrganize the data you observe in the following scenario into a\nmathematical notation, using the techniques we've covered in this\nchapter. Then come up with a hypothesis to explain this data:\n\n-   You come home from work and notice that your front door is open and\n    the side window is broken. As you walk inside, you immediately\n    notice that your laptop is missing.\n\n$$\nP(\\text{door open, window broken, laptop missing} \\mid H_{hausbreaking})\n$$\n:::\n\n------------------------------------------------------------------------\n\n::: {#exr-01-3}\nThe following scenario adds data to the previous one. Demonstrate how\nthis new information changes your beliefs and come up with a second\nhypothesis to explain the data, using the notation you've learned in\nthis chapter.\n\n- A neighborhood child runs up to you and apologizes profusely for\naccidentally throwing a rock through your window. They claim that they\nsaw the laptop and didn't want it stolen so they opened the front door\nto grab it, and your laptop is safe at their house.\n\n$$\nP(\\text{door open, window broken, laptop missing, child explains} \\mid H_{accident})\n$$\n:::\n",
    "supporting": [
      "01-everyday-reasoning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}