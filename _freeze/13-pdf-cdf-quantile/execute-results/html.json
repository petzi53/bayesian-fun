{
  "hash": "bc43aa00059cdb57eb1a91f5d618874e",
  "result": {
    "markdown": "# Tools of Parameter Estimation: The PDF, CDF, and Quantile Function\n\n> This chapter will cover more on the\n> <a class='glossary' title='A probability density function (pdf) tells us the probability that a random variable takes on a certain value. (Statology) The probability density function (PDF) for a given value of random variable X represents the density of probability (probability per unit random variable) within a particular range of that random variable X. Probability densities can take values larger than 1. (StackExchange Mathematics) We can use a continuous probability distribution to calculate the probability that a random variable lies within an interval of possible values. To do this, we use the continuous analogue of a sum, an integral. However, we recognise that calculating an integral is equivalent to calculating the area under a probability density curve. We use p(value) for probability densities and Pr for probabilities. (Bayesian Statistics, Chap.3)'>probability density function</a> (PDF); introduce the\n> <a class='glossary' title='A cumulative distribution function (CDF) tells us the probability that a random variable takes on a value less than or equal to x. (Statology) It sums all parts of the distribution, replacing a lot of calculus work. The CDF takes in a value and returns the probability of getting that value or lower. (BF, Chap.13) A CDF is a hypothetical model of a distribution, the ECDF models empirical (i.e. observed) data. (Statistics How To)'>cumulative distribution function</a> (CDF), which helps us\n> more easily determine the probability of ranges of values; and\n> introduce <a class='glossary' title='Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities (Wikipedia)'>quantiles</a>, which divide our\n> probability distributions into parts with equal probabilities. For\n> example, a *percentile* is a 100-quantile, meaning it divides the\n> probability distribution into 100 equal pieces. (115)\n\n## Estimating the Conversion Rate for an Email Signup List\n\n> Say you run a blog and want to know the probability that a visitor to\n> your blog will subscribe to your email list. In marketing terms,\n> getting a user to perform a desired event is referred to as the\n> *conversion event*, or simply a *conversion*, and the probability that\n> a user will subscribe is the *conversion rate*.\n\n> As discussed in @sec-beta-distribution, we would use the beta\n> distribution to estimate p, the probability of subscribing, when we\n> know `k`, the number of people subscribed, and `n`, the total number\n> of visitors. The two parameters needed for the beta distribution are\n> `α`, which in this case represents the total subscribed (`k`), and\n> `β`, representing the total not subscribed (`n – k`).\n\n## The Probability Density Function\n\n> let's say for the first 40,000 visitors, you get 300 subscribers. The\n> PDF for our problem is the beta distribution where α = 300 and β =\n> 39,700.\n\n::: {#thm-mean-beta}\n#### Computing the mean of the beta distribution\n\n$$\n\\begin{align*}\n\\mu_{Beta} = \\frac{\\alpha}{\\alpha + \\beta} \\\\\n\\mu_{Beta} = \\frac{300}{300 + 39,700} = 0.0075\n\\end{align*}\n$$ {#eq-mean-beta}\n\nThe blog's average conversion rate is simply\n$\\frac{subscribed}{visited}$.\n:::\n\n### Visualizing and Interpreting the PDF\n\n![Visualizing the beta PDF for our beliefs in the true conversion\nrate](img/13fig01.jpg){#fig-13-01\nfig-alt=\"The beta PDF as almost a normal distribution with mode = mean at .0075\"\nfig-align=\"center\" width=\"70%\"}\n\n> Given that we have uncertainty in our measurement, and we have a mean,\n> it could be useful to investigate how much more likely it is that the\n> true conversion rate is 0.001 higher or lower than the mean of 0.0075\n> we observed.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-integrate-higher-lower lst-cap=\"How much more likely it is that the true conversion rate is 0.001 higher or lower\"}\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0, 0.0065)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.007978686 with absolute error < 3.8e-07\n```\n\n\n:::\n\n```{.r .cell-code #lst-integrate-higher-lower lst-cap=\"How much more likely it is that the true conversion rate is 0.001 higher or lower\"}\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0.0085, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.01248151 with absolute error < 9.4e-09\n```\n\n\n:::\n:::\n\n\n> if we had to make a decision with the limited data we have, we could\n> still calculate how much likelier one extreme is than the other:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-integrate-extremes lst-cap=\"How much likelier is one extreme than the other\"}\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0.0085, 1)[[\"value\"]] /\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0, 0.0065)[[\"value\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 1.564357\n```\n\n\n:::\n:::\n\n\nIt's 56 percent more likely that our true conversion rate is greater\nthan 0.0085 than that it's lower than 0.0065.\n\n### Working with the PDF in R\n\nI am going to use my own code in @sec-replicate-fig-13-1. But to see what it looks like I use the R base code lines from the book:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-draw-pdf-with-base-r lst-cap=\"Working with the PDF in base R\"}\nxs <- seq(0.005, 0.01, by = 0.00001)\nxs.all <- seq(0, 1, by = 0.0001)\nplot(\n    xs,\n    dbeta(xs, 300, 40000 - 300),\n    type = 'l',\n    lwd = 3,\n    ylab = \"density\",\n    xlab = \"probability of subscription\",\n    main = \"PDF Beta(300,39700)\"\n)\n```\n\n::: {.cell-output-display}\n![](13-pdf-cdf-quantile_files/figure-html/draw-pdf-with-base-r-1.png){width=672}\n:::\n:::\n\n\n\n\n## Introducing the Cumulative Distribution Function\n\n> we can save ourselves a lot of effort with the cumulative distribution\n> function (CDF), which sums all parts of our distribution, replacing a\n> lot of calculus work. ... The CDF takes in a value and returns the\n> probability of getting that value or lower.\n\n> The CDF gets this probability by taking the cumulative area under the\n> curve for the PDF (for those comfortable with calculus, the CDF is the\n> *anti-derivative* of the PDF). We can summarize this process in two\n> steps: (1) figure out the cumulative area under the curve for each\n> value of the PDF, and (2) plot those values. That's our CDF.\n\n![Visualizing the cumulative area under the\ncurve](img/13fig02.jpg){#fig-13-02\nfig-alt=\"Visualizing the cumulative area under the curve of the beta distribution in steps to 0.0005\"\nfig-align=\"center\" width=\"70%\"}\n\n@fig-13-02 shows the cumulative area under the curve for the PDF of\nBeta(300,39700). As you can see, our cumulative area under the curve\ntakes into account all of the area in the pieces to its left.\n\nUsing this approach, as we move along the PDF, we take into account an\nincreasingly higher probability until our total area is 1, or complete\ncertainty. To turn this into the CDF, we can imagine a function that\nlooks at only these areas under the curve.\n\n@fig-13-03 shows what happens if we plot the area under the curve for\neach of our points, which are 0.0005 apart.\n\n![Plotting just the cumulative probability from\n@fig-13-02](img/13fig03.jpg){#fig-13-03\nfig-alt=\"Plotting the area under the curve for each of our points, which are 0.0005 apart results in an S curve\"\nfig-align=\"center\" width=\"70%\"}\n\n> Now we have a way of visualizing just how the cumulative area under\n> the curve changes as we move along the values for our PDF. Of course,\n> the problem is that we're using these discrete chunks. In reality, the\n> CDF just uses infinitely small pieces of the PDF, so we get a nice\n> smooth line as seen in @fig-13-04.\n\n![The CDF for our problem](img/13fig04.jpg){#fig-13-04\nfig-alt=\"The CDF for our problem of conversion to blog subscriber\"\nfig-align=\"center\" width=\"70%\"}\n\n### Visualizing and Interpreting the CDF\n\n> The PDF is most useful visually for quickly estimating where the peak\n> of a distribution is, and for getting a rough sense of the width\n> (variance) and shape of a distribution. However, with the PDF it is\n> very difficult to reason about the probability of various ranges\n> visually. The CDF is a much better tool for this.\n\n#### Finding the median {#sec-finding-the-median}\n\n> Unlike the mean, computing the median can actually be pretty tricky.\n> For small, discrete cases, it's as simple as putting your observations\n> in order and selecting the value in the middle. But for continuous\n> distributions like our beta distribution, it's a little more\n> complicated.\n\n> Thankfully, we can easily spot the median on a visualization of the\n> CDF. We can simply draw a line from the point where the cumulative\n> probability is 0.5, meaning 50 percent of the values are below this\n> point and 50 percent are above.\n\n::: callout-note\nThere are many packages about the beta functions out there that provides\nfunctions for parameter calculation: For instance `betamedian()` of\n[{**betafunctions**}](https://search.r-project.org/CRAN/refmans/betafunctions/html/betamedian.html).\nBut in a [StackOverflow\npost](https://stackoverflow.com/questions/59077866/is-there-a-way-to-find-the-median-using-beta-distribution-parameters-in-r)\nis the suggestion simple to use `qbeta()` with `p = 0.5`.\n\nThis is what I have done in replicating @fig-13-05 with my @fig-pb-13-5.\n:::\n\n![Estimating the median visually using the\nCDF](img/13fig05.jpg){#fig-13-05\nfig-alt=\"Estimating the median visually using the CDF\"\nfig-align=\"center\" width=\"70%\"}\n\n#### Approximating Integrals Visually\n\n> When working with ranges of probabilities, we'll often want to know\n> the probability that the true value lies somewhere between some value\n> y and some value x.\n\nTime-consuming computation the integration with R is not necessary as we\ncan eyeball whether or not a certain range of values has a very high\nprobability or a very low probability of occurring.\n\n![Visually performing integration using the\nCDF](img/13fig06.jpg){#fig-13-06\nfig-alt=\"Visually performing integration using the CDF\"\nfig-align=\"center\" width=\"70%\"}\n\n#### Estimating Confidence Intervals\n\n> Looking at the probability of ranges of values leads us to a very\n> important concept in probability: the confidence interval. A\n> confidence interval is a lower and upper bound of values, typically\n> centered on the mean, describing a range of high probability, usually\n> 95, 99, or 99.9 percent. When we say something like \"The 95 percent\n> confidence interval is from 12 to 20,\" what we mean is that there is a\n> 95 percent probability that our true measurement is somewhere between\n> 12 and 20. Confidence intervals provide a good method of describing\n> the range of possibilities when we're dealing with uncertain\n> information.\n\nIn spite of a special note \"*In Bayesian statistics what we are calling\na \"confidence interval\" can go by a few other names, such as \"critical\nregion\" or \"critical interval.\" In some more traditional schools of\nstatistics, \"confidence interval\" has a slightly different meaning,\nwhich is beyond the scope of this book.*\" this concept and notions are\nnot correct for Bayesian statistics. At least what I have learned\nreading other books, especially [@mcelreath2020].\n\n::: {.callout-warning}\n<a class='glossary' title='Also known as evidential probability, is the process of adding prior probability to a hypothesis and adjusting that probability as new information becomes available. Unlike traditional frequentist probability which only accounts for the previous frequency of an event to predicate and outcome, the Bayesian model begins with an initial set of subjective assumptions (prior probability) and adjusts them accordingly through trial and experimentation (posterior probability). Instead of only rejecting or failing to reject a null hypothesis, Bayesian probability allows someone to quantify how much confidence they should have in a particular result. (&lt;a href”https://deepai.org/machine-learning-glossary-and-terms/bayesian-probability&quot;&gt;deepai.org)'>Bayesian statistics</a> talks about <a class='glossary' title='Two parameter values that contain between them a specified amount of posterior probability, a probability mass, is usually known as confidence interval in FREQUENTIST STATISTICS and credible interval in BAYESIAN STATISTICS.'>credible intervals</a>  that have a very different meaning as the <a class='glossary' title='A range of values, calculated from the sample observations, that is believed, with a particular probability, to contain the true parameter value. (Cambridge Dictionary of Statistics, 4th ed., p.98)'>confidence intervals</a>  of <a class='glossary' title='Also known as frequentist interference, is a type of statistical approach where conclusions are made based on the frequency of an event. This statistical approach determines the probability of a long-term experiment, meaning the experiment is repeated under the same set of conditions to obtain an outcome. In frequentist statistics the population parameters are fixed, but unknown, and the data observed in experiments are random. (deepai.org)'>frequentist statistics</a> McElreath even proposes the notion of <a class='glossary' title='Two parameter values that contain between them a specified amount of posterior probability, a probability mass, is usually know as confidence interval that may instead be called a credible interval. We’re going to call it a compatibility interval instead, in order to avoid the unwarranted implications of “confidence”” and “credibility.” What the interval indicates is a range of parameter values compatible with the model and data. The model and data themselves may not inspire confidence, in which case the interval will not either. (Chap.3)'>compatibility intervals</a>.\n:::\n\n> Say we wanted to know the range that covers 80 percent of the possible values for the true conversion rate. We solve this problem by combining our previous approaches: we draw lines at the y-axis from 0.1 and 0.9 to cover 80 percent, and then simply see where on the x-axis these intersect with our CDF:\n\n![Estimating our confidence intervals visually using the\nCDF](img/13fig07.jpg){#fig-13-07\nfig-alt=\"Estimating our confidence intervals visually using the CDF\"\nfig-align=\"center\" width=\"70%\"}\n\n### Using the CDF in R\n\n> Just as nearly all major PDFs have a function starting with $d$, like `dnorm()`, CDF functions start with $p$, such as `pnorm()`.\n\n::: {.callout-note}\nThis is a new information for me. Now I understand better the differences and use cases of the different types of distribution. My comprehension will be fostered with the next section when the application of function starting with $q$ is explained.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-calc-beta-less-0.0065 lst-cap=\"Calculate the probability that Beta(300,39700) is less than 0.0065\"}\npbeta(0.0065,300,39700)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.007978686\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code #lst-calc-beta-greater-0.0085 lst-cap=\"Calculate the true probability that the conversion rate is greater than 0.0085\"}\npbeta(1,300,39700) - pbeta(0.0085,300,39700)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.01248151\n```\n\n\n:::\n:::\n\n\n> The great thing about CDFs is that it doesn’t matter if your distribution is discrete or continuous. If we wanted to determine the probability of getting three or fewer heads in five coin tosses, for example, we would use the CDF for the binomial distribution like this:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-calc-beta-3-or-fewer-heads-5-tosses lst-cap=\"Calculate the probability of getting three or fewer heads in five coin tosses\"}\npbinom(3, 5, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.8125\n```\n\n\n:::\n:::\n\n\n\n\n## The Quantile Function\n\n> Mathematically, the CDF is like any other function in that it takes an $x$ value, often representing the value we’re trying to estimate, and gives us a $y$ value, which represents the cumulative probability. But there is no obvious way to do this in reverse; that is, we can’t give the same function a $y$ to get an $x$.\n\nBut we did reversing the function when we estimated the median in @sec-finding-the-median respectively in my version in @sec-replicate-figure-13-5.\n\n> The inverse of the CDF is an incredibly common and useful tool called the quantile function. To compute an exact value for our median and confidence interval, we need to use the quantile function for the beta distribution. \n\n### Visualizing and Understanding the Quantile Function\n\n> Because the quantile function is simply the inverse of the CDF, it just looks like the CDF rotated 90 degrees, as shown in @fig-13-08.\n\n![Visually, the quantile function is just a rotation of the CDF](img/13fig08.jpg){#fig-13-08\nfig-alt=\"Visually, the quantile function is just a rotation of the CDF\"\nfig-align=\"center\" width=\"70%\"}\n\n> Whenever you hear phrases like:\n>\n> - “The top 10 percent of students …”\n> - “The bottom 20 percent of earners earn less than …”\n> - “The top quartile has notably better performance than …”\n>\n> you’re talking about values that are found using the quantile function\n\n### Calculating Quantiles in R\n\nWe are using the function `qnorm()` for calculating <a class='glossary' title='Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities (Wikipedia)'>quantiles</a>.\n\n> For example, if we want to know the value that 99.9 percent of the distribution is less than, we can use qbeta() with the quantile we’re interested in calculating as the first argument, and the alpha and beta parameters of our beta distribution as the second and third arguments, like so:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-qbeta-less-99.9 lst-cap=\"Value that we 99.9 percent certain that the true conversion rate for our emails is less than 0.0089\"}\nqbeta(0.999, 300, 39700)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.008903462\n```\n\n\n:::\n:::\n\n\nThe result is 0.0089, meaning we can be 99.9 percent certain that the true conversion rate for our emails is less than 0.0089.\n\nWith the quantile function we can also calculate the 95% confidence interval by finding the lower and upper 2.5% quantile:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-get-95-conf-int lst-cap=\"Calculate the 95% confidence interval\"}\nglue::glue(\"The lower bound is {round(qbeta(0.025,300,39700), 7)} and the upper bound is {round(qbeta(0.975,300,39700) ,7)}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> The lower bound is 0.0066781 and the upper bound is 0.0083686.\n```\n\n\n:::\n:::\n\n> Now we can confidently say that we are 95 percent certain that the real conversion rate for blog visitors is somewhere between 0.67 percent and 0.84 percent. … Suppose an article on your blog goes viral and gets 100,000 visitors. Based on our calculations, we know that we should expect between 670 and 840 new email subscribers.\n\n\n## Wrapping Up\n\n## Exercises\n\nTry answering the following questions to see how well you understand the\ntools of parameter estimation. The solutions can be found at\nhttps://nostarch.com/learnbayes/.\n\n### Exercise 13-1\n\nUsing the code example for plotting the PDF on page 127, plot the CDF\nand quantile functions.\n\n- For the CDF see @lst-fig-pb-13-4a and @fig-pb-13-4a.\n- For the quantile function see @lst-fig-pb-13-8 and @fig-pb-13-8.\n\n### Exercise 13-2\n\nReturning to the task of measuring snowfall from @sec-chap-10, say you\nhave the following measurements (in inches) of snowfall: 7.8, 9.4, 10.0,\n7.9, 9.4, 7.0, 7.0, 7.1, 8.9, 7.4\n\nWhat is your 99.9 percent confidence interval for the true value of\nsnowfall?\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-13-2 lst-cap=\"Calculate the 99% confidence interval\"}\nx <-  c(7.8, 9.4, 10.0, 7.9, 9.4, 7.0, 7.0, 7.1, 8.9, 7.4)\n\nglue::glue(\"The lower bound is {round(qnorm(0.0005,mean(x), sd(x)), 2)} and the upper bound is {round(qnorm(0.9995,mean(x), sd(x)), 2)}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> The lower bound is 4.46 and the upper bound is 11.92.\n```\n\n\n:::\n:::\n\n::: {.callout-warning}\nBesides that in my try I used the `sd_fun()` function from @lst-comp-sigma-with-own-function, I commit an error in using bounds of 0.001 and 0.999 instead of 0.0005 and 0.9995.\n:::\n\n### Exercise 13-3\n\nA child is going door to door selling candy bars. So far she has visited\n30 houses and sold 10 candy bars. She will visit 40 more houses today.\nWhat is the 95 percent confidence interval for how many candy bars she\nwill sell the rest of the day?\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-13-3 lst-cap=\"Calculate the 95 percent confidence interval for how many candy bars will be sold\"}\nglue::glue(\"The lower bound is {round(qbeta(0.025, 10, 20), 2)}% and the upper bound is {round(qbeta(0.975, 10, 20), 2)}%.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> The lower bound is 0.18% and the upper bound is 0.51%.\n```\n\n\n:::\n\n```{.r .cell-code #lst-exr-13-3 lst-cap=\"Calculate the 95 percent confidence interval for how many candy bars will be sold\"}\nglue::glue(\"This means that she will with 95% probability get between 40 * 0.18 = {40 * 0.18} and 40 * 0.51 = {40 * 0.51} candy bars.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> This means that she will with 95% probability get between 40 * 0.18 = 7.2 and 40 * 0.51 = 20.4 candy bars.\n```\n\n\n:::\n\n```{.r .cell-code #lst-exr-13-3 lst-cap=\"Calculate the 95 percent confidence interval for how many candy bars will be sold\"}\nglue::glue(\"But she can only sell complete bars: Therefore she will sell between {floor(40 * 0.18)} and {floor(40 * 0.51)} candy bars.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> But she can only sell complete bars: Therefore she will sell between 7 and 20 candy bars.\n```\n\n\n:::\n:::\n\n\n\n## Experiments\n\nI started with @fig-pb-13-4a because this is the easiest graph, as it\nreplicates @fig-13-04 with just the CDF and nothing else. So maybe you\nwill begin also with this basic plot. After @fig-pb-13-4a the natural\nsequence -- ordered by complexity -- is @fig-pb-13-3. After that you can\ninspect in detail my different tries with @fig-13-02 (@fig-pb-13-2a,\n@fig-pb-13-2b and my best solution @fig-pb-13-2c) . Then follow my\nsequences here from @fig-13-05 to @fig-13-08.\n\n::: callout-important\nThere is the following system in using distributions with R, exemplified\nwith the normal distribution:\n\n-   `dnorm` for plotting probability densities functions (PDFs).\n-   `pnorm` for plotting cumulative distribution functions (CDFs).\n-   `qnorm` for plotting quantile functions, it is the reverse of CDFs.\n-   `rnorm` for generating and plotting random distributions.\n\nSee\n\n1.  R help file for [Distributions in the stats\n    package](https://rdrr.io/r/stats/Distributions.html).\n2.  [The distribution\n    zoo](https://ben18785.shinyapps.io/distribution-zoo/) (a shiny\n    application by [Ben Lambert](https://ben-lambert.com/bayesian/) &\n    [Fergus\n    Cooper](https://www.cs.ox.ac.uk/people/fergus.cooper/site/)). See\n    for the code the [GitHub\n    repo](https://github.com/ben18785/distribution-zoo).\n:::\n\n### Replicate Figure 13-1 {#sec-replicate-fig-13-1}\n\n#### Wrong dimension of x-axis for Figure 13-1\n\nAt first I got the following graph:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble::tibble(x = seq(0, 1, .0001),\n               y = dbeta(x, 300, 39700)) |> \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n```\n\n::: {.cell-output-display}\n![](13-pdf-cdf-quantile_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThe problem here is that the interesting part of the PDF is very small\nas we know from the $\\frac{300}{40000} = 0.0075$. Therefore it does not\nmake sense to spread the grid from 0 to 1. We get a much better\nvisualization in the area 0 to 001:\n\n#### Better dimension of x-axis but still not identical for Figure 13-1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble::tibble(x = seq(0, 0.01, .0001),\n               y = dbeta(x, 300, 39700)) |> \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n```\n\n::: {.cell-output-display}\n![](13-pdf-cdf-quantile_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nBut even this curve is not optimal. Now let's try the interval \\[0.005,\n0.01\\]:\n\n#### Optimal dimension of x-axis but grid too wide for smooth Figure 13-1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble::tibble(x = seq(0.005, 0.01, .0001),\n               y = dbeta(x, 300, 39700)) |> \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n```\n\n::: {.cell-output-display}\n![](13-pdf-cdf-quantile_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nIt turns out that this is the interval also used in the book example.\nBut in my visualization you can see some irregularity at the top,\nbecause my grid has too coarse. It has only 51 values. Let's try a much\nfiner grid with 5001 values:\n\n#### Optimal replication of Figure 13-1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble::tibble(x = seq(0.005, 0.01, .00001),\n               y = dbeta(x, 300, 39700)) |> \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n```\n\n::: {.cell-output-display}\n![](13-pdf-cdf-quantile_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n### Replicate Figure 13-2\n\n#### First try (bad)\n\n::: callout-note\nI had to learn about the difference between `annotate(geom = \"text\" …)`\nand `annotate(geom = \"label\" …)`. There are two big differences:\n\n-   `geom_text()` does not understand the `fill` aesthetics, e.g. you\n    can't change the background color of the text.\n-   `geom_label()` \"is considerable slower than geom_text()\" and does\n    not support the `check_overlap` argument and the `angle` aesthetic.\n    But more important for my use case `geom_label()` draws a rectangle\n    around the label. You need to add `label.size = NA` to remove the\n    label. Although the option `label.size` is documented (\"Size of\n    label border, in mm.\") using `NA` to remove the border completely is\n    not explained. I had to find out it the hard way via\n    [StackOverflow](https://stackoverflow.com/a/58242703/7322615).\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-2a lst-cap=\"Highlighting the cumulative area under the curve\"}\nx_lower <-  seq(0.006, 0.0085, 0.0005)\nx_upper <-  seq(0.0065, 0.009, 0.0005)\ntext_pos <- seq(0.00625, 0.00875, 0.0005)\ncolors <- c(\"gray90\", \"gray80\", \"gray70\", \"gray50\", \"gray40\", \"black\") \n\ndf_13_2 <- \ntibble::tibble(x = seq(0.006, 0.009, length.out = 6000),\n               y = dbeta(x, 300, 39700))\n\nggplot2::ggplot(df_13_2, ggplot2::aes(x = x, y = y)) +\nggplot2::geom_line() +\n        ggplot2::geom_area(data = df_13_2 |>\n                           dplyr::filter(x >= x_lower[1] & x <  x_upper[1]),\n                           fill = colors[1]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[1], \n                          size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA,\n                          label = round(integrate(function(x) \n                  dbeta(x, 300, 39700), x_lower[1], x_upper[1])[[\"value\"]], 3)) +\n    \n        ggplot2::geom_area(data = df_13_2 |> \n                           dplyr::filter(x >= x_lower[2] & x <  x_upper[2]),\n                           fill = colors[2]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[2], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA,\n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[2])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |> \n                           dplyr::filter(x >= x_lower[3] & x <  x_upper[3]),\n                           fill = colors[3]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[3], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[3])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |> \n                           dplyr::filter(x >= x_lower[4] & x <  x_upper[4]),\n                           fill = colors[4]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[4], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[4])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |> \n                           dplyr::filter(x >= x_lower[5] & x <  x_upper[5]),\n                           fill = colors[5]\n                           ) +\n        ggplot2::annotate(\"label\", x = text_pos[5], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[5])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |> \n                           dplyr::filter(x >= x_lower[6] & x <  x_upper[6]),\n                           fill = colors[6]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[6], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[6])[[\"value\"]], 3)) +\n\nggplot2::theme_bw() +\nggplot2::labs(\n    title = \"Visualizing the cumulative area under the curve\",\n    x = \"Probability of Subscription\",\n    y = \"Density\"\n)\n```\n\n::: {.cell-output-display}\n![Visualizing the cumulative area under the curve](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-2a-1.png){#fig-pb-13-2a fig-align='center' width=70%}\n:::\n:::\n\n\n#### Second try (Slightly better)\n\n::: callout-warning\nI am very unhappy about the many duplicates of @lst-fig-pb-13-2a. I\ntried to use loops or vectorized commands but the best I found out is\n@lst-fig-pb-13-2b with has still six duplicate code lines.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-2b lst-cap=\"Highlighting the cumulative area under the curve\"}\nx_lower <-  seq(0.006, 0.0085, 0.0005)\nx_upper <-  seq(0.0065, 0.009, 0.0005)\nlabel_x_pos <- seq(0.00625, 0.00875, 0.0005)\ncolors <- c(\"gray90\", \"gray80\", \"gray70\", \"gray50\", \"gray40\", \"black\") \n\ncum_rate = 0\nfor (i in 1:6) {\n    cum_rate[i] <- \n    round(integrate(function(x) \n                      dbeta(x, 300, 39700), x_lower[1], x_upper[i])[[\"value\"]], 3) \n}\n\nadd_label <- function(x_pos, txt) {\n    ggplot2::annotate(\n        geom = \"label\",\n        x = x_pos,\n        y = 125,\n        size = 5,\n        label = txt,\n        label.size = NA\n    )\n}\n\n\nhighlight_one_area <- function(df, i) {\n        ggplot2::geom_area(data = df |>\n                       dplyr::filter(x >= x_lower[i] & x <  x_upper[i]),\n                       fill = colors[i])\n}\n\n\n\ndf_13_2 <- \n    tibble::tibble(x = seq(0.006, 0.009, length.out = 6000),\n                   y = dbeta(x, 300, 39700)) \n\n\np_13_2 <- \n    ggplot2::ggplot(df_13_2, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    highlight_one_area(df_13_2, 1) +\n    highlight_one_area(df_13_2, 2) +\n    highlight_one_area(df_13_2, 3) +\n    highlight_one_area(df_13_2, 4) +\n    highlight_one_area(df_13_2, 5) +\n    highlight_one_area(df_13_2, 6) +\n    add_label(label_x_pos, cum_rate) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Visualizing the cumulative area under the curve\",\n        x = \"Probability of Subscription\",\n        y = \"Density\"\n    )\n\np_13_2\n```\n\n::: {.cell-output-display}\n![Visualizing the cumulative area under the curve](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-2b-1.png){#fig-pb-13-2b fig-align='center' width=70%}\n:::\n:::\n\n\n#### Third try (My best version)\n\nAs I could not find a better solution for @lst-fig-pb-13-2b myself I\nposted my question in\n[StackOverflow](https://stackoverflow.com/questions/77182234/ggplot2-shade-several-areas-under-the-curve-using-a-loop)\nand got an answer with two different options within one hour!\n\nThe first solution is to use `lapply()`. I should have known that as I\ncame over a similar\n[solution](https://stackoverflow.com/a/18089991/7322615). The second\nsolution is for me more complex and I have still to study it thoroughly\nto understand it.\n\nWhat follows in @lst-fig-pb-13-2c is the modern take of `lapply()` using\nthe `purrr::map()` function. (I do not understand why I had to use\nexactly the argument \"df\" and asked via SO comment.)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-2c lst-cap=\"Highlighting the cumulative area under the curve\"}\n########### Vectors ##############\n\nx_lower <-  seq(0.006, 0.0085, 0.0005)\nx_upper <-  seq(0.0065, 0.009, 0.0005)\nlabel_x_pos <- seq(0.00625, 0.00875, 0.0005)\ncolors <- c(\"gray90\", \"gray80\", \"gray70\", \"gray50\", \"gray40\", \"black\") \n\n########### Functions ############\n\n\ncum_rate = 0\nfor (i in 1:6) {\n    cum_rate[i] <- \n    round(integrate(function(x) \n                      dbeta(x, 300, 39700), x_lower[1], x_upper[i])[[\"value\"]], 3) \n}\n\nadd_label <- function(x_pos, txt) {\n    ggplot2::annotate(\n        geom = \"label\",\n        x = x_pos,\n        y = 125,\n        size = 5,\n        label = txt,\n        label.size = NA\n    )\n}\n\nhighlight_areas <- function(df, i) {\n        ggplot2::geom_area(data = df |>\n                       dplyr::filter(x >= x_lower[i] & x <  x_upper[i]),\n                       fill = colors[i])\n}\n\n######### Graph plotting ############\n\ndf_13_2 <- \n    tibble::tibble(x = seq(0.006, 0.009, length.out = 6000),\n                   y = dbeta(x, 300, 39700)) \n\np_13_2 <- \n    ggplot2::ggplot(df_13_2, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    purrr::map(1:6, highlight_areas, df = df_13_2) +\n    add_label(label_x_pos, cum_rate) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Visualizing the cumulative area under the curve\",\n        x = \"Probability of Subscription\",\n        y = \"Density\"\n    )\n\np_13_2\n```\n\n::: {.cell-output-display}\n![Visualizing the cumulative area under the curve](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-2c-1.png){#fig-pb-13-2c fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 13-3\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-3 lst-cap=\"Plot the cumulative area under the curve\"}\ndf_13_3 <- \ntibble::tibble(x = seq(0.006, 0.009, 0.0005),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_3, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_point() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The cumulative distribution function\",\n        x = \"Subscription rate\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output-display}\n![Plotting just the cumulative probability from Figure 13-2](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-3-1.png){#fig-pb-13-3 fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 13-4\n\n#### Cumulative Distribution Function (CDF)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-4a lst-cap=\"Plot the Cumulative Distribution Function (CDF)\"}\ndf_13_4a <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_4a, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The cumulative distribution function\",\n        x = \"Subscription rate\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output-display}\n![The CDF for our problem](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-4a-1.png){#fig-pb-13-4a fig-align='center' width=70%}\n:::\n:::\n\n\n#### Empiricial Cumulative Distribution Function (ECDF) - with steps\n\n::: callout-note\nTrying to apply the CDF I noticed that there is also an\n`r`glossary(\"ECDF\")\\` (Empirical Cumulative Distribution Function). The\ndifferences are that the ECDF is a step function whereas the CDF is\nsmooth. But with many different values the ECDF approximates to ta\nsmooth function.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-4b lst-cap=\"Plot the Empirical Cumulative Distribution Function (ECDF)\"}\ndf_13_4b <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-4),\n               y = rbeta(x, 300, 39700)) \n\n\nggplot2::ggplot(df_13_4b, ggplot2::aes(y)) +\n    ggplot2::stat_ecdf(geom = \"step\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The empirical cumulative distribution function (ECDF)\",\n        x = \"x\",\n        y = \"ECDF\"\n    )\n```\n\n::: {.cell-output-display}\n![The ECDF for our problem](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-4b-1.png){#fig-pb-13-4b fig-align='center' width=70%}\n:::\n:::\n\n\n#### Empiricial Cumulative Distribution Function (ECDF) - with points\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-4c lst-cap=\"Plot the Cumulative Distribution Function (CDF)\"}\ndf_13_4c <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-4),\n               y = rbeta(x, 300, 39700)) \n\n\nggplot2::ggplot(df_13_4c, ggplot2::aes(y)) +\n    ggplot2::stat_ecdf(geom = \"point\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The empirical cumulative distribution function (ECDF)\",\n        x = \"x\",\n        y = \"ECDF\"\n    )\n```\n\n::: {.cell-output-display}\n![The ECDF for our problem](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-4c-1.png){#fig-pb-13-4c fig-align='center' width=70%}\n:::\n:::\n\n\n#### Empiricial Cumulative Distribution Function (ECDF) - smooth\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-4d lst-cap=\"Plot the Empirical Cumulative Distribution Function (ECDF)\"}\ndf_13_4d <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = rbeta(x, 300, 39700)) \n\n\nggplot2::ggplot(df_13_4d, ggplot2::aes(y)) +\n    ggplot2::stat_ecdf(geom = \"step\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The empirical cumulative distribution function (ECDF)\",\n        x = \"x\",\n        y = \"ECDF\"\n    )\n```\n\n::: {.cell-output-display}\n![The ECDF for our problem](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-4d-1.png){#fig-pb-13-4d fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 13-5 {#sec-replicate-figure-13-5}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-15 lst-cap=\"Estimate and display median using the CDF\"}\nmedian_beta <- round(qbeta(0.5, 300, 39700), 5)\n\ndf_13_5 <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_5, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(ggplot2::aes(x = 0.005, y = 0.50, \n                          xend = median_beta, yend = 0.50),\n                          lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n                          size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(ggplot2::aes(x = median_beta, y = 0.50, \n                      xend = median_beta, yend = 0.00),\n                      lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n                      size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::annotate(\"text\", y = 0.625, x = 0.0087,\n                      label = \"median = qbeta(0.5, 300, 39700)\") +\n        ggplot2::annotate(\"text\", y = 0.55, x = 0.0087,\n                      label = glue::glue(\"= {median_beta}\")) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating median\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Estimating the median visually using the CDF](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-5-1.png){#fig-pb-13-5 fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 13-6 {#sec-replicate-figure-13-6}\n\nIn contrast to @fig-pb-13-5 where I cheated by calculating the median of\nthe beta distribution I will in @sec-replicate-figure-13-6 try to approximate the\nintegration just visually.\n\nWe are going to estimate the range between p(x \\> 0.0075 and x \\<\n0.0085). The solution could be visually done approximately either with a\nruler or (not so exact) just by eyeballing. To do it programmatically\nwithout integration is a somewhat complex procedure with four steps:\n\n1.  First I have to draw vertical lines from the start and end of the\n    interesting range. These lines have to cross the CDF because I do\n    not know the value of the cumulative probability where they meet the\n    CDF.\n2.  Then I have to inspect the intersection visually and try to estimate\n    and draw the horizontal lines. This has to be done several times\n    until the two lines cross (almost) exactly at the CDF.\n3.  Now I can limit the vertical and horizontal lines, so that they stop\n    at the CDF.\n4.  The last step is to estimate the range by reading the intersection\n    at the y-axis.\n\n#### First step\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-6a lst-cap=\"Approximate the integration of a range of the CDF: First step\"}\ndf_13_6 <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_vline(xintercept = 0.0075, color = \"steelblue\",\n                        linetype = \"dashed\") +\n    ggplot2::geom_vline(xintercept = 0.0085, color = \"steelblue\",\n                        linetype = \"dashed\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x > 0.0075 and x < 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output-display}\n![Visually performing integration using the CDF: First step](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-6a-1.png){#fig-pb-13-6a fig-align='center' width=70%}\n:::\n:::\n\n\n#### Second step\n\nThe lower cumulative probability is almost exact 0.5 as I can see and\nalready know from @fig-pb-13-5. Without knowing the solution in the book\nmy first approach was to draw a line at 0.98% of the CDF (orange). As\nthis seems a little to less a tried with it .99%\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-6b lst-cap=\"Approximate the integration of a range of the CDF: Second step\"}\ndf_13_6 <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_vline(xintercept = 0.0075, color = \"steelblue\",\n                        linetype = \"dashed\") +\n    ggplot2::geom_vline(xintercept = 0.0085, color = \"steelblue\",\n                        linetype = \"dashed\") +\n\n    ggplot2::geom_hline(yintercept = 0.5, color = \"steelblue\",\n                    linetype = \"dashed\") +\n    ggplot2::geom_hline(yintercept = 0.98, color = \"orange\",\n        linetype = \"dashed\") +\n    ggplot2::geom_hline(yintercept = 0.99, color = \"steelblue\",\n            linetype = \"dashed\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x > 0.0075 and x < 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output-display}\n![Visually performing integration using the CDF: Second step](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-6b-1.png){#fig-pb-13-6b fig-align='center' width=70%}\n:::\n:::\n\n\n#### Third step\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-6c lst-cap=\"Approximate the integration of a range of the CDF: Third step\"}\ndf_13_6 <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.005, yend = 0.50, \n              x = 0.00750, y = 0.50),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0075, yend = 0.50, \n              x = 0.0075, y = 0.00),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0,\n              xend = 0.0085, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0.99,\n              xend = 0.005, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n  \n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x > 0.0075 and x < 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output-display}\n![Visually performing integration using the CDF: Third step](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-6c-1.png){#fig-pb-13-6c fig-align='center' width=70%}\n:::\n:::\n\n\n#### Fourth step\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-6d lst-cap=\"Approximate the integration of a range of the CDF: Fourth step\"}\ndf_13_6 <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.005, yend = 0.50, \n              x = 0.00750, y = 0.50),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0075, yend = 0.50, \n              x = 0.0075, y = 0.00),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0,\n              xend = 0.0085, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0.99,\n              xend = 0.005, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n        \n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0055, y = 0.5,\n              xend = 0.0055, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"red\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0055, yend = 0.5,\n              x = 0.0055, y = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"red\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::annotate(\"text\", x = 0.0058, y = 0.75,\n                      label = \"~ 0.49\", color = \"red\", size = 5) +\n  \n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x > 0.0075 and x < 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output-display}\n![Visually performing integration using the CDF: Fourth step](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-6d-1.png){#fig-pb-13-6d fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 13-7\n\nThere is nothing new for approximating the range that covers 80 percent of the possible values for the true conversion rate. We use the same strategy as in @sec-replicate-figure-13-6 but this time starting from the y-axis:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-7 lst-cap=\"Approximate the confidence interval via the CDF\"}\ndf_13_7 <- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_7, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.007, yend = 0.125, \n              x = 0.005, y = 0.125),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0080, yend = 0.875, \n              x = 0.005, y = 0.875),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.007, y = 0.125,\n              xend = 0.007, yend = 0.0),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.008, y = 0.875,\n              xend = 0.008, yend = 0.0),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n  \n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating 80% Confidence Interval\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output-display}\n![Estimating our confidence intervals visually using the CDF](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-7-1.png){#fig-pb-13-7 fig-align='center' width=70%}\n:::\n:::\n\n\n\n### Replicate Figure 13-8\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-pb-13-8 lst-cap=\"Plot the quantile function\"}\ndf_13_8 <- \ntibble::tibble(x = seq(0, 1, 1e-4),\n               y = qbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_8, ggplot2::aes(x = x, y = y)) +\n    ggplot2::ylim(0.006, 0.009) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Quantile Function Beta(300, 39700)\",\n        x = \"Subscription rate\",\n        y = \"Cumulative Probability\"\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Removed 7 rows containing missing values (`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Visually, the quantile function is just a rotation of the CDF.](13-pdf-cdf-quantile_files/figure-html/fig-pb-13-8-1.png){#fig-pb-13-8 fig-align='center' width=70%}\n:::\n:::\n",
    "supporting": [
      "13-pdf-cdf-quantile_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}