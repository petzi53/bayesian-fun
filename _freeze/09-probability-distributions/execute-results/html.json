{
  "hash": "4e735a15f57ae66e2b4a1d4e5018de5f",
  "result": {
    "markdown": "---\nengine: knitr\n---\n\n\n# Bayesian Priors and Working with Probability Distributions\n\n## C-3PO’s Asteroid Field Doubts\n\n> As an example, we’ll use one of the most memorable errors in statistical analysis from a scene in *Star Wars: The Empire Strikes Back*. When Han Solo, attempting to evade enemy fighters, flies the *Millennium Falcon* into an asteroid field, the ever-knowledgeable C-3PO informs Han that probability isn’t on his side. C-3PO says, “Sir, the possibility of successfully navigating an asteroid field is approximately 3,720 to 1!” (78)\n\n## Determining C-3PO’s Beliefs\n\n\n***\n::: {#thm-beta-dist}\n#### Parameterization of the Beta Distribution\n\n> Recall that the beta distribution is parameterized with an $\\alpha$ (number of observed successes) and a $\\beta$ (the number of observed failures) (79):\n\n$$\nP(\\text{Rate Of Success} | \\text{Successes and Failures}) = Beta(\\alpha,\\beta)\n$$ {#eq-beta-dist}\n:::\n***\n\n> Let’s say that C-3PO has records of 2 people surviving the asteroid field, and 7,440 people ending their trip in a glorious explosion! (79)\n\n![A beta distribution representing C-3PO’s belief that Han will survive](img/09fig01.jpg){#fig-09-01\nfig-alt=\"Distribution of  C-3PO’s Likelihood of Surviving\"\nfig-align=\"center\" width=\"70%\"}\n\n## Accounting for Han’s Badassery\n\n> We have a *prior belief* that Han will make it through the asteroid field, because Han has survived every improbable situation so far. (80)\n\n> We’ll start with some sort of upper bound on Han’s badassery. If we believed Han absolutely could not die, the movie would become predictable and boring. At the other end, our belief that Han will succeed is stronger than C-3PO’s belief that he won’t, so let’s say that our belief that Han will survive is 20,000 to 1. (81)\n\n![The beta distribution representing the range of our prior belief in Han Solo’s survival](img/09fig02.jpg){#fig-09-02\nfig-alt=\"Distribution of our prior belief of Han Solo surviving\"\nfig-align=\"center\" width=\"70%\"}\n\n## Creating Suspense with a Posterior\n\nBy combining the different beliefs, C-3PO’s belief about the small changes of success (<a class='glossary' title='The likelihood function (often simply called the likelihood) is the joint probability (or probability density) of observed data viewed as a function of the parameters of a statistical model. (Wikipedia) It indicates how likely a particular population is to produce an observed sample. (&lt;a href=“https://www.statistics.com/glossary/likelihood-function/&gt;statistics.com) It is the probability of the data given our beliefs about the data: P(data | belief). (BF, Chap.8)'>likelihood</a> and our belief about the skills of Han Solo (<a class='glossary' title='The Prior Probability, also called the Prior, is the assumed probability distribution before we have seen the data. (Wikipedia) It quantifies how likely our initial belief is: P(belief). (BF, Chap.8)'>prior</a>), we create the <a class='glossary' title='It is the revised or updated probability of an event occurring after taking into consideration new information. (Investopedia). Posterior probability = prior probability + new evidence (called likelihood). (Statistics How To) The posterior distribution will be a distribution of Gaussian distributions. (SR, Chap.4). It quantifies exactly how much our observed data changes our beliefs: P(belief | data) (BF, Chap.8)'>posterior probability</a>.\n\n***\n::: {#thm-prop-bayes}\n#### Proportional Form of Bayes’ theorem\n\n$$Posterior \\propto Likelihood \\times Prior $$ {#eq-prop-bayes}\nThe sign $\\propto$ is the <a class='glossary' title='The proportional symbol (∝) is pronounced als “varies as” or “is proportional to”. (UEfAP) It is produced in Markdown with $\\propto$. (List of LaTeX mathematical symbols)'>proportional operator</a> and stands for \"is proportional to\".\n\n:::\n***\n\n> Remember, using this proportional form of Bayes’ theorem means that our posterior distribution doesn’t necessarily sum to 1. But we’re lucky because there’s an easy way to combine beta distributions that will give us a normalized posterior when all we have is the likelihood and the prior. (82)\n\n***\n::: {#thm-normalized-beta-posterior}\n#### Normalized Posterior with just Likelihood and Beta\n\n$$\nBeta(\\alpha_{posterior},\\beta_{posterior}) = Beta(\\alpha_{likelihood} + \\alpha_{prior}, \\beta_{likelihood} + \\beta_{prior})\n$$ {#eq-normalized-beta-posterior}\n:::\n***\n\nWith our example:\n\n$$\n\\begin{align*}\nBeta(?,?) = Beta(2 + 20000, 7400 + 1) \\\\\nBeta(20002,7401) = Beta(2 + 20000, 7400 + 1)\n\\end{align*}\n$$\n\n![Combining likelihood with prior gives the more intriguing posterior](img/09fig03.jpg){#fig-09-03\nfig-alt=\"Distribution of prior belief Beta(2 + 20000, 7400 + 1)\"\nfig-align=\"center\" width=\"70%\"}\n\nThe combined belief of C-3PO for the very low chances to live through the asteroid field and our prior belief of the exceptional skills of Han Solo accounts to a pretty good 73% chance of survival. \n\n## Wrapping Up\n\nThe chapter provides two learnings:\n\n1. The prior provides important background information that is essential to get realistic expectations for the probability distribution of the posterior.\n2. Instead of using a single probability (some central measure, like mean, median etc.) you can express express a range of possible beliefs.  The best way is to use the whole probability distributions, rather than a summary like a single probability or range of the distribution.\n\n## Exercises\n\nTry answering the following questions to see if you understand how to combine prior probability and likelihood distributions to come up with an accurate posterior distribution; solutions to the questions can be found at [https://nostarch.com/learnbayes/](https://nostarch.com/learnbayes/).\n\n### Exercise 9-1\n\nA friend finds a coin on the ground, flips it, and gets six heads in a row and then one tails. Give the beta distribution that describes this. Use integration to determine the probability that the true rate of flipping heads is between 0.4 and 0.6, reflecting that the coin is reasonably fair.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-9-1 lst-cap=\"Probability that the true rate of flipping heads is between 0.4 and 0.6\"}\nintegrate(function(p) dbeta(p, 6, 1), 0.4, 0.6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.04256 with absolute error < 4.7e-16\n```\n\n\n:::\n:::\n\n\nThere is only a 4% probability that the coin is fair, at least based only on the likelihood probability. \n\n\n### Exercise 9-2\n\nCome up with a prior probability that the coin *is* fair. Use a beta distribution such that there is at least a 95 percent chance that the true rate of flipping heads is between 0.4 and 0.6.\n\n::: {.callout-note}\nI could note solve this problem, because I did not come up with the idea that 'any $\\alpha$ prior = $\\beta$ prior will give us a “fair” prior; and the larger those values are, the stronger that prior is.' (240)\n\nSo the solution is: \n\n`integrate(function(p) dbeta(p, 6 + added_prior, 1 + added_prior), 0.4, 0.6)`. \n\nTo get at least 95% change that the coin is fair we need to determine the value of the added prior. Instead of trial and error manually I will do it with a little R program.  \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-9-2 lst-cap=\"Change the prior so that the beta distribution will show at least a 95 percent chance that the true rate of flipping heads is between 0.4 and 0.6.\"}\nadded_prior = NULL\n\nfor (i in 1:100) {\n    j <- integrate(function(p) dbeta(p, 6 + i, 1 + i), 0.4, 0.6)\n    if (j$value >= .95) {\n       print(glue::glue('{i}: {j$value}'))\n       added_prior = i\n       break\n    }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 54: 0.950427480766883\n```\n\n\n:::\n:::\n\n\n\nThe nearest value of the prior to get at least a 95 percent chance that the true rate of flipping heads is between 0.4 and 0.6 is 54. This is slightly lower than the trial & error solution in the Appendix C of the book.\n\n### Exercise 9-3\n\nNow see how many more heads (with no more tails) it would take to convince you that there is a reasonable chance that the coin is *not* fair. In this case, let’s say that this means that our belief in the rate of the coin being between 0.4 and 0.6 drops below 0.5.\n\nWith our added prior value we have a beta distribution of Beta(6 + 54, 1 + 54).\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-9-3 lst-cap=\"How mandy more heads in a row are necessary that our belief of a fair coin drop under 50%?\"}\nfor (i in 1:100) {\n    j <- integrate(function(p) dbeta(p, 6 + added_prior + i, 1 + added_prior), 0.4, 0.6)\n    if (j$value <= .50) {\n       print(glue::glue('{i}: {j$value}'))\n       break\n    }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 23: 0.481467889312114\n```\n\n\n:::\n:::\n\nTo drop our expectation under 50% we need 23 more heads in row.\n\n> This shows that even a strong prior belief can be overcome with more data. (241)\n\n\n## Experiments\n\n### Replicating Figure 9-1\n\n> Let’s say that C-3PO has records of 2 people surviving the asteroid field, and 7,440 people ending their trip in a glorious explosion! (79)\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-fig-repl-9-1 lst-cap=\"Replication of Figure 9.1: Distribution of  C-3PO’s Likelihood of Surviving\"}\ntibble::tibble(x = seq(from = 0, to = 0.003, by = 0.00001),\n                    y = dbeta(x, 2, 7440)) |> \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Distribution of  C-3PO’s Likelihood of Surviving\",\n        x = \"Probability\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![A beta distribution representing C-3PO’s belief that Han will survive](09-probability-distributions_files/figure-html/fig-repl-9-1-1.png){#fig-repl-9-1 width=672}\n:::\n:::\n\n\n### Replicating Figure 9-2\n\nOur belief that Han will succeed is 20,000 to 1.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-fig-repl-9-2 lst-cap=\"Replication of Figure 9.2: Distribution of our prior belief of Han Solo surviving\"}\ntibble::tibble(x = seq(from = 0.99900, to = 1, by = 0.00001),\n                    y = dbeta(x, 20000, 1)) |> \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Distribution of our prior belief of Han Solo surviving\",\n        x = \"Probability of success\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![The beta distribution representing the range of our prior belief in Han Solo’s survival](09-probability-distributions_files/figure-html/fig-repl-9-2-1.png){#fig-repl-9-2 width=672}\n:::\n:::\n\n\n\n### Replicating Figure 9-3\n\nCombining the distributions of prior ($Beta(2, 20000)$) and likelihood ($Beta(7400, 1)$) generates the posterior distribution of $Beta(20002, 7401)$.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-fig-repl-9-3 lst-cap=\"Replication of Figure 9.3: Distribution of prior belief Beta(2 + 20000, 7400 + 1)\"}\ntibble::tibble(x = seq(from = 0.6, to = 0.8, by = 0.001),\n                    y = dbeta(x, 20002, 7401)) |> \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Distribution of prior belief Beta(2 + 20000, 7400 + 1)\",\n        x = \"Probability of success\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![Combining likelihood with the prior gives thea more intriguing posterior.](09-probability-distributions_files/figure-html/fig-repl-9-3-1.png){#fig-repl-9-3 width=672}\n:::\n:::\n",
    "supporting": [
      "09-probability-distributions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}