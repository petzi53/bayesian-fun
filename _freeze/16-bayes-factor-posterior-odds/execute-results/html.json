{
  "hash": "6a78a73c72fe7563fdfd745b6fc138e7",
  "result": {
    "markdown": "---\nengine: knitr\n---\n\n\n# Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas\n\n> The <a class='glossary' title='The Bayes factor is a ratio of two competing statistical models represented by their evidence, and is used to quantify the support for one model over the other. (Wikipedia)'>Bayes factor</a> is a formula that tests the plausibility of one hypothesis by comparing it to another. The result tells us how many times more likely one hypothesis is than the other.\n\n## Revisiting Bayes’ Theorem\n\n$$\nP(H \\mid D) = \\frac{{P(H)} \\times  P(D \\mid H) }{P(D)}\n$$ {#eq-bayes-theorem}\n\n- $P(H \\mid D)$: <a class='glossary' title='It is the revised or updated probability of an event occurring after taking into consideration new information. (Investopedia). Posterior probability = prior probability + new evidence (called likelihood). (Statistics How To) The posterior distribution will be a distribution of Gaussian distributions. (SR, Chap.4). It quantifies exactly how much our observed data changes our beliefs: P(belief | data) (BF, Chap.8)'>Posterior Probability</a>, which tells us how strongly we should believe in our hypothesis, given our data.\n- $P(H)$: <a class='glossary' title='The Prior Probability, also called the Prior, is the assumed probability distribution before we have seen the data. (Wikipedia) It quantifies how likely our initial belief is: P(belief). (BF, Chap.8)'>Prior Probability</a> or Prior Belief, the probability of our hypothesis prior to looking at the data.\n- $P(D \\mid H)$: <a class='glossary' title='The likelihood function (often simply called the likelihood) is the joint probability (or probability density) of observed data viewed as a function of the parameters of a statistical model. (Wikipedia) It indicates how likely a particular population is to produce an observed sample. (&lt;a href=“https://www.statistics.com/glossary/likelihood-function/&gt;statistics.com) It is the probability of the data given our beliefs about the data: P(data | belief). (BF, Chap.8)'>Likelihood</a> of getting the existing data if our hypothesis were true.\n- $P(D)$ is the probability of the data observed independent of the hypothesis. We need P(D) in order to make sure that our posterior probability is correctly placed somewhere between 0 and 1.\n\n> $P(D)$ is … totally unnecessary if all we care about is comparing the relative strength of two different hypotheses. … For these reasons, we often use the *proportional form* of <a class='glossary' title='This is the theorem that gives Bayesian data analysis its name. But the theorem itself is a trivial implication of probability theory. The mathematical definition of the posterior distribution arises from Bayes’ Theorem. The key lesson is that the posterior is proportional to the product of the prior and the probability of the data. (Chap.2)'>Bayes’ theorem</a>.\n\n$$P(H \\mid D) \\propto P(H) \\times P(D \\mid H)$$ {#eq-bayes-prop}\n\n> the posterior probability of our hypothesis is proportional to the prior multiplied by the likelihood. We can use this to compare two hypotheses by examining the ratio of the prior belief multiplied by the likelihood for each hypothesis using the *ratio of posteriors* formula:\n\n$$\\frac{P(H_{1}) \\times P(D \\mid H_{1})}{P(H_{2}) \\times P(D \\mid H_{2})}$$ {#eq-posterior-ratio}\n\n\n> if the ratio is 2, then $H_{1}$ explains the observed data twice as well as $H_{2}$, and if the ratio is $\\frac{1}{2}$, then $H_{2}$ explains the data twice as well as $H_{1}$.\n\n## Building a Hypothesis Test Using the Ratio of Posteriors\n\n> The ratio of posteriors formula gives us the *posterior odds*, which allows us to test hypotheses or beliefs we have about data. \n\n> To better understand the posterior odds, we’ll break down the ratio of posteriors formula into two parts: the likelihood ratio, or the Bayes factor, and the ratio of prior probabilities.\n\n### The Bayes Factor\n\n$$\\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})}$$ {#eq-bayes-factor}\n\n> What this ratio tells us is the likelihood of what we’ve seen given what *we* believe to be true compared to what *someone else* believes to be true.\n\n> The key here is that in Bayesian reasoning, we don’t worry about supporting our beliefs—we are focused on how well our beliefs support the data we observe. In the end, data can either confirm our ideas or lead us to change our minds.\n\n### Prior Odds\n\n> So far we have assumed that the prior probability of each hypothesis is the same. This is clearly not always the case: a hypothesis may explain the data well even if it is very unlikely. \n\n$$\\frac{P(H_{1})}{P(H_{2})}$$\n\n> This ratio compares the probability of two hypotheses before we look at the data. When used in relation to the Bayes factor, this ratio is called the prior odds in our $H_{1}$ and written as $O(H_{1})$. This representation is helpful because it lets us easily note how strongly (or weakly) we believe in the hypothesis we’re testing. When this number is greater than 1, it means the prior odds favor our hypothesis, and when it is a fraction less than 1, it means they’re against our hypothesis. For example, $O(H_{1}) = 100$$ means that, without any other information, we believe $H_{1}$ is 100 times more likely than the alternative hypothesis.\n\n### Posterior Odds\n\n$$\\text{posterior odds} = O(H_{1})\\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})}$$ {#eq-posterior-odds}\n\n| Posterior odds | Strength of evidence                |\n|----------------|-------------------------------------|\n| 1 to 3         | Interesting, but nothing conclusive |\n| 3 to 20        | Looks like we’re on to something    |\n| 20 to 150      | Strong evidence in favor of $H_{1}$      |\n| > 150          | Overwhelming evidence               |\n\n: Guidelines for Evaluating Posterior Odds {#tbl-guidelines-odds}\n\n### Empty: Guidelines for Evaluating Posterior Odds\n\n### Empty: Self-Diagnosing Rare Diseases Online\n\n## Wrapping Up\n\n\n",
    "supporting": [
      "16-bayes-factor-posterior-odds_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}