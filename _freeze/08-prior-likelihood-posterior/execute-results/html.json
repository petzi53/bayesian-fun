{
  "hash": "f97a078ed4b0699c294c3bba1c416262",
  "result": {
    "markdown": "---\nengine: knitr\n---\n\n\n# The Prior, Likelihood, and Posterior of Bayes’ Theorem\n\n## The Three Parts\n\n<a class='glossary' title='This is the theorem that gives Bayesian data analysis its name. But the theorem itself is a trivial implication of probability theory. The mathematical definition of the posterior distribution arises from Bayes’ Theorem. The key lesson is that the posterior is proportional to the product of the prior and the probability of the data. (Chap.2)'>Bayes’ theorem</a> has three parts: \n\n1. <a class='glossary' title='The Prior Probability, also called the Prior, is the assumed probability distribution before we have seen the data. (Wikipedia) It quantifies how likely our initial belief is: P(belief). (BF, Chap.8)'>Prior Probability</a>, $P(belief)$\n2. <a class='glossary' title='The likelihood function (often simply called the likelihood) is the joint probability (or probability density) of observed data viewed as a function of the parameters of a statistical model. (Wikipedia) It indicates how likely a particular population is to produce an observed sample. (&lt;a href=“https://www.statistics.com/glossary/likelihood-function/&gt;statistics.com) It is the probability of the data given our beliefs about the data: P(data | belief). (BF, Chap.8)'>Likelihood</a>, $P(data | belief)$ and the \n3. <a class='glossary' title='It is the revised or updated probability of an event occurring after taking into consideration new information. (Investopedia). Posterior probability = prior probability + new evidence (called likelihood). (Statistics How To) The posterior distribution will be a distribution of Gaussian distributions. (SR, Chap.4). It quantifies exactly how much our observed data changes our beliefs: P(belief | data) (BF, Chap.8)'>Posterior Probability</a>, $P(belief | data)$.\n\nThe fourth part of Bayes’ theorem, probability of the data, $P(data)$ is used to normalize the posterior so it accurately reflects a probability from 0 to 1. In practice, we don’t always need P(data), so this value doesn’t have a special name.\n\n![The different parts of Bayes’ theorem](img/08fig01.jpg){#fig-08-01\nfig-alt=\"The different parts of Bayes’ theorem\"\nfig-align=\"center\" width=\"70%\"}\n\n## Investigating the Scene of a Crime\n\nKurt explains again Bayes’ theorem with an example: This time the probability of being robbed after finding that the is window broken, the front door is open, and a laptop is missing. One of the differences in the explanation with this example is the explicit use of the different parts of Bayes’ rule and the missing of data. He shows how to bypass missing data by comparing alternative hypotheses.\n\n## empty: Considering Alternative Hypotheses\n\n\n## Comparing Our Unnormalized Posteriors\n\nIf you compare alternative hypotheses than both the numerator and denominator contain P(data), so that you can remove it and still maintain the ratio.\n\n## empty: Wrapping Up\n\n## Exercises\n\nTry answering the following questions to see if you have a solid understanding of the different parts of Bayes’ Theorem. The solutions can be found at https://nostarch.com/learnbayes/.\n\n### Exercise 8-1 {#sec-exercise-8-1}\n\nAs mentioned, you might disagree with the original probability $P(robbed) = \\frac{1}{1000}$ assigned to the likelihood:\n\n$P(\\text{broken window, open front door, missing laptop | robbed}) = \\frac{3}{10}$\n\n\nHow much does this change our strength in believing $H_{1}$ over $H_{2}$? (In the example in the text $H_{1}$ explained what has observed 6,570 times better than $H_{2}$. In the example the posterior probability of $H_{2}$ was calculated with $\\frac{1}{21,900,000}$\n\n$$\n\\begin{align*}\n\\frac{\\frac{1}{1,000} \\times \\frac{3}{10}}{\\frac{1}{21,900.000}} = \\frac{\\frac{3}{10,000}}{\\frac{1}{21,900,000}} = \\frac{65,700,000}{10,000} = 657\n\n\\end{align*}\n$$\nThe result still favors $H_{1}$, but the difference is much smaller now.\n\n\n### Exercise 8-2\n\nHow unlikely would you have to believe being robbed is—our prior for $H_{1}$—in order for the ratio of $H_{1}$ to $H_{2}$ to be even?\n\n$$\n\\begin{align*}\n\\frac{\\frac{1}{1,000} \\times \\frac{1}{21,900}}{\\frac{1}{21,900.000}} = \\frac{\\frac{1}{21,900,000}}{\\frac{1}{21,900,000}} = 1\n\n\\end{align*}\n$$\n::: {.callout-warning}\nI misunderstood the question of the exercise: I did not take into account the updated belief from @sec-exercise-8-1. But the solution has the same principle: It would need an extremely unlikely belief, so that both hypotheses would be equally possible. \n\nBy the way: The high unlikeliness of $H_{2}$ is a result in estimating each aspect of the data (broken window, open front door, and missing laptop) separately. Using the #eq-product-rule by multiplying the probability of all three events has resulted in an extremely low prior probability. I am therefore not sure if it is a good idea to estimate each factor individually. \n:::\n\n\n\n",
    "supporting": [
      "08-prior-likelihood-posterior_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}