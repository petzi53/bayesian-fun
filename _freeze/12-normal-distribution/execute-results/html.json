{
  "hash": "82b320f90022dbc303984b56f0d9c619",
  "result": {
    "markdown": "# The Normal Distribution\n\n## Measuring Fuses for Dastardly Deeds\n\nSetting up fuses and measuring how long it takes them to burn through to make sure one has 18 seconds to get away. The times recorded (in seconds) for each fuse to burn through are: 19, 22, 20, 19, 23.\n\n> Calculating the mean gives us μ = 20.6, and calculating the standard deviation gives us σ = 1.62.\n\nKeep in mind that R computes the standard deviation dividing by $n - 1$ instead of just $n$ as in the book. so we have to use again our own function as developed in @lst-compute-sd.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-comp-mean lst-cap=\"Compute mean\"}\n(mu <- mean(c(19, 22, 20, 19, 23)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 20.6\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code #lst-comp-sigma-with-r-function lst-cap=\"Compute standard deviation with base R function\"}\n(sigma1 <- sd(c(19, 22, 20, 19, 23)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 1.81659\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code #lst-comp-sigma-with-own-function lst-cap=\"Compute standard deviation with own function\"}\nsd_fun <- function(x) {\n  sqrt(sum((x - mean(x))^2) * 1 / length(x))\n}\n\n(sigma2 <- sd_fun(c(19, 22, 20, 19, 23)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 1.624808\n```\n\n\n:::\n:::\n\n\n## The Normal Distribution\n\n> The normal distribution is a continuous probability distribution (like the beta distribution in @sec-beta-distribution) that best describes the strength of possible beliefs in the value of an uncertain measurement, given a known mean and standard deviation. (104)\n\n![A normal distribution with μ = 0 and σ = 1](img/12fig03.jpg){#fig-12-03\nfig-alt=\"A normal distribution with mu = 0 and sigma = 1\"\nfig-align=\"center\" width=\"70%\"}\n\n::: {layout-ncol=2}\n![A normal distribution with μ = 0 and σ = 0.5](img/12fig04.jpg){#fig-12-04\nfig-alt=\"A normal distribution with mu = 0 and sigma = 0.5\"}\n\n![A normal distribution with μ = 0 and σ = 2](img/12fig05.jpg){#fig-12-05\nfig-alt=\"A normal distribution with mu = 0 and sigma = 2\" width=\"70%\"}\n:::\n\n## Solving the Fuse Problem\n\n![A normal distribution with μ = 20.6 and σ = 1.62](img/12fig06.jpg){#fig-12-06\nfig-alt=\"A normal distribution with mu = 20.6 and sigma = 1.62\" width=\"70%\"}\n\nWhat is the probability, given the data observed, that the fuse will run for 18 seconds or less? \n\n![The area under the curve that we’re interested in](img/12fig07.jpg){#fig-12-07\nfig-alt=\"A normal distribution with mu = 20.6 and sigma = 1.62\" width=\"70%\"}\n\nThe area of the shaded region represents the probability of the fuse lasting 18 seconds or less given the observations. Notice that even though none of the observed values was less than 18, because of the spread of the observations, the normal distribution in @fig-12-06 shows that a value of 18 or less is still possible. \n\nBy integrating over all values less than 18, we can calculate the probability that the fuse will not last as long as our villain needs it to.\n\n> We can see that the line in the PDF is nearly flat at 10, meaning there is virtually no probability in this region, so we can just integrate from 10 to 18. We could also choose a lower value, like 0, but because there’s effectively no probability in this region, it won’t change our result in any meaningful way.\n\nI am using 0, because this value is more intuitive for me.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-integrating-0-to-18 lst-cap=\"Integrating over all values less than 18 seconds\"}\nintegrate(function(x)\n    dnorm(x, mean = 20.6, sd = 1.62), 0, 18)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.05425369 with absolute error < 3.5e-05\n```\n\n\n:::\n:::\n\nThe same result but a smaller error in my version: < 3e-11 vs. < 3.5e-05\n\n> Rounding the value, we can see that `P(fuse time < 18) = 0.05`, telling us there is a 5 percent chance that the fuse will last 18 seconds or less.\n\n## Some Tricks and Intuitions\n\n> For *any* normal distribution with a known mean and standard deviation, you can estimate the area under the curve around `μ` in terms of `σ`.\n\n**Distance from the mean**\n\n- `1σ`: 68%\n- `2σ`: 95%\n- `3σ`: 99,7%\n\n![Sixty-eight percent of the probability density (area under the curve) lies between one standard deviation of the mean in either direction.](img/12fig08.jpg){#fig-12-08\nfig-alt=\"Sixty-eight percent of the probability density (area under the curve) lies between one standard deviation of the mean in either direction.\" width=\"70%\"}\n\n> This little trick is very useful for quickly assessing the likelihood of a value given even a small sample. … Even when we *do* want to use R to integrate, this trick can be useful for determining a minimum or maximum value to integrate from or to. \n\n## \"N Sigma\" Events\n\n> “the fall of the stock price was an eight-sigma event.” What this expression means is that the observed data is eight standard deviations from the mean. We saw the progression of one, two, and three standard deviations from the mean, which were values at 68, 95, and 99.7 percent, respectively. You can easily intuit from this that an eight-sigma event must be extremely unlikely. \n\n::: {.callout-warning}\nIf you ever see data that is 5 or more standard deviation away from the mean: Check you distribution because it could be a that your data didn't come from a normal distribution.\n:::\n\n## The Beta Distribution and the Normal Distribution\n\n> You may remember from @sec-beta-distribution that the beta distribution allows us to estimate the true probability given that we have observed `α` desired outcomes and `β` undesired outcomes, where the total number of outcomes is `α + β`. Based on that, you might take some issue with the notion that the normal distribution is truly the best method to model parameter estimation given that we know only the mean and standard deviation of any given data set. After all, we could describe a situation where `α = 3` and `β = 4` by simply observing three values of `1` and four values of `0`. This would give us `μ = 0.43` and `σ = 0.53`. We can then compare the beta distribution with `α = 3` and `β = 4` to a normal distribution with `μ = 0.43` and `σ = 0.53`, as shown in @fig-12-09.\n\n![Comparing the beta distribution to the normal distribution](img/12fig09.jpg){#fig-12-09\nfig-alt=\"The beta distribution is flatter than the normal distribution but extends his tails to both sides wider\" width=\"70%\"}\n\n> It’s clear that these distributions are quite different. We can see that for both distributions the center of mass appears in roughly the same place, but the bounds for the normal distribution extend way beyond the limits of our graph. This demonstrates a key point:\n\n::: {.callout-important}\n##### Beta or Normal Distribution?\n\nOnly when you know nothing about the data other than its mean and variance is it safe to assume a normal distribution.  The following differences could help for a decision:\n\n- **Beta distribution**: The value we’re looking for must lie in the range 0 to 1. \n- **Normal distribution** is defined from –∞ to ∞, which often includes values that cannot possibly exist.\n:::\n\n## Exercises\n\nTry answering the following questions to see how well you understand the normal distribution. The solutions can be found at https://nostarch.com/learnbayes/.\n\n### Exercise 12-1\n\nWhat is the probability of observing a value five sigma greater than the mean or more?\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-1 lst-cap=\"Probability of value greater than 5 sigma\"}\np <- integrate(dnorm, -5, 5)\n(1 - p[[\"value\"]]) / 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2.866516e-07\n```\n\n\n:::\n:::\n\n\n::: {.callout-warning}\nAlthough I got almost exact the same result, my solution is very different than in the \"Answers to the Exercises\" (p.242) of the book:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-1-book-answer lst-cap=\"Book solution for exercise 12-1\"}\nintegrate(function(x)\n    dnorm(x, mean = 0, sd = 1), 5, 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 2.88167e-07 with absolute error < 5.6e-07\n```\n\n\n:::\n:::\n\n\nThe rationale for my approach is the idea that it is known that `integrate(dnorm, -1.96, 1.96)` results in 0.9500042%. (I took this example from the [R help file](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/integrate).)\n\nThe result is the probability that a value is between two standard deviations. Therefore the probability of 1 minus the result of the integration is the probability of values outside this integration. As the normal distribution is symmetric we got the value higher than twice the sd after dividing by 2.\n\nWhat applies for 2 standard deviations is also valid for other values of sigma.\n:::\n\n\n### Exercise 12-2\n\nA fever is any temperature greater than 100.4 degrees Fahrenheit. Given the following measurements, what is the probability that the patient has a fever?\n100.0, 99.8, 101.0, 100.5, 99.7\n\nI am going to use the `sd_fun()` function instead of the sample standard deviation.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-2 lst-cap=\"Probability of fever with measurements of 100.0, 99.8, 101.0, 100.5, 99.7\"}\ntemp <-  c(100.0, 99.8, 101.0, 100.5, 99.7)\nintegrate(function(x)\n    dnorm(x, mean(temp), sd_fun(temp)), 100.4, Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.3402821 with absolute error < 2.8e-09\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-warning}\nMy first try didn't succeed because I used `temp` instead `x` as the first parameter for the `dnorm()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-2-wrong lst-cap=\"Wrong integration by using the temp vector instead of x\"}\ntemp <-  c(100.0, 99.8, 101.0, 100.5, 99.7)\n\nintegrate(function(x)\n    dnorm(temp, mean(temp), sd_fun(temp)), 100.4, Inf)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\n#> Error in integrate(function(x) dnorm(temp, mean(temp), sd_fun(temp)), : evaluation of function gave a result of wrong length\n```\n\n\n:::\n:::\n\n\nI used `Inf` as upper value for the integration and not $200$, but I go exactly the same result.\n\n:::\n\n### Exercise 12-3 {#sec-exr-12-3}\n\nSuppose in Chapter 11 we tried to measure the depth of a well by timing coin drops and got the following values: 2.5, 3, 3.5, 4, 2\n\nThe distance an object falls can be calculated (in meters) with the following formula:\n\n$$distance = \\frac{1}{2} \\times G \\times time^2$$\n\nwhere G is 9.8 m/s/s. What is the probability that the well is over 500 meters deep?\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-3 lst-cap=\"Probability that the well is over 500 meters deep: My solution\"}\nt <-  c(2.5, 3, 3.5, 4, 2)\ns <-  t^2 * 0.5 * 9.8\nintegrate(function(x)\n    dnorm(x, mean(s), sd_fun(s)), 500, Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 8.844762e-105 with absolute error < 3.2e-106\n```\n\n\n:::\n:::\n\nIt is practically impossible that the well is over 500 meters deep.\n\nLet's check the result by a manual estimation: The longest fall is 4 seconds. $4^2$ seconds = 16 times 10 (=approx. G)  = 160, divided by 2 = 80 meter. Even the longest fall infers only a 80 meter deep well.\n\n::: {.callout-warning}\nAgain the solution in the book takes a complete different approach. I have converted the measured fall times of seconds into distances in meter and then applied the `integrate()` function. The books solution took the more complex way to calculate the time it would need for 500 meter:\n\n$$\n\\begin{align*}\n500 = \\frac{1}{2} \\times G \\times time^2 \\\\\ntime^2 = \\frac{500}{\\frac{1}{2} \\times G} \\\\\ntime = sqrt(\\frac{500}{\\frac{1}{2} \\times G}) \\\\\ntime = sqrt(\\frac{500}{\\frac{1}{2} G \\times 9.8}) \\\\\ntime = 10.10153\n\\end{align*}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-3-book lst-cap=\"Probability that the well is over 500 meters deep: Book solution\"}\nt <-  c(2.5, 3, 3.5, 4, 2)\nintegrate(function(x)\n    dnorm(x, mean(t), sd_fun(t)), 10.1, Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 5.036701e-24 with absolute error < 3.9e-27\n```\n\n\n:::\n:::\n\n\nBoth result are almost zero but my calculation is much nearer zero than the solution of the book. I think that the difference arises from the very different values for the standard deviation. In my case it is `sd_fun(s)` = 20.8897523 meter and in the book solution it is `sd_fun(t)` = 0.7071068 seconds, e.g. a value much smaller.\n\n\n:::\n\n### Exercise 12-4\n\nWhat is the probability there is no well (i.e., the well is really 0 meters deep)? You’ll notice that probability is higher than you might expect, given your observation that there is a well. There are two good explanations for this probability being higher than it should. The first is that the normal distribution is a poor model for our measurements; the second is that, when making up numbers for an example, I chose values that you likely wouldn’t see in real life. Which is more likely to you?\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-4 lst-cap=\"Probability if there is no well\"}\nt <-  c(2.5, 3, 3.5, 4, 2)\nintegrate(function(x)\n    dnorm(x, mean(t), sd_fun(t)), -1, 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 1.103754e-05 with absolute error < 1.2e-19\n```\n\n\n:::\n:::\n\nNormally the first idea is that the analyst has chosen a wrong model. But in this case I am sure that the normal distribution is a correct one. So it only remains that the data are not valid. And in fact I noticed it already in the beginning (starting with @sec-exr-12-3) that the measurement are too spread out from 2 to 4 seconds. Such a big difference should not occur in reality.\n\n::: {.callout-warning}\nI have to confess that I did not compute correctly: Instead to integrate between -1 and 0, I integrated from 0 to Inf. The result was a nonsensical probability of 99.99%, essentially saying: \"Yes, there is a well, because the coins need time from 0 second to infinity to reach the bottom.\"\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-exr-12-4-wrong lst-cap=\"Wrong computation results in nonsensical probability of 99,99%\"}\nt <-  c(2.5, 3, 3.5, 4, 2)\nintegrate(function(x)\n    dnorm(x, mean(t), sd_fun(t)), 0, Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.999989 with absolute error < 2.9e-05\n```\n\n\n:::\n:::\n\n:::\n\n\n## Experiments\n\n### Replicate Figure 12-3\n\n**Figure 12-3 (Book, p.105), but here it is @fig-12-03.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-norm-dist lst-cap=\"Replicate Figure 12-3: Normal distribution with μ of 0 and σ of 1\"}\nggplot2::ggplot(data.frame(x = c(-5, 5)), \n                ggplot2::aes(x = x)) +\n    ggplot2::stat_function(fun = dnorm) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Normal distribution with a mean of 0 and a standard deviation of 1\",\n        x = \"Value\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![Normal distribution with μ of 0 and σ of 1](12-normal-distribution_files/figure-html/fig-norm-dist-1.png){#fig-norm-dist fig-align='center' width=70%}\n:::\n:::\n\n### Replicate Figure 12-4 & 12-5\n\n**Figure 12-4 and 12-5 (Book, p.106f.), here it is @fig-12-04 and @fig-12-05**\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-fig-norm-dist1 lst-cap=\"Replicate Figure 12-4: Normal distribution with μ of 0 and σ of 0.5\"}\np1 <- \n    ggplot2::ggplot(data.frame(x = c(-5, 5)), \n                    ggplot2::aes(x = x)) +\n        ggplot2::stat_function(fun = function(x) dnorm(x, 0, 0.5)) +\n        ggplot2::theme_bw() +\n        ggplot2::labs(\n            x = \"Value\",\n            y = \"Density\"\n        )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code #lst-fig-norm-dist2 lst-cap=\"Replicate Figure 12-5: Normal distribution with μ of 0 and σ of 1\"}\np2 <- \n    ggplot2::ggplot(data.frame(x = c(-5, 5)), \n                    ggplot2::aes(x = x)) +\n        ggplot2::stat_function(fun = function(x) dnorm(x, 0, 2)) +\n        ggplot2::theme_bw() +\n        ggplot2::labs(\n            x = \"Value\",\n            y = \"Density\"\n        )\n```\n:::\n\n\n\nI am trying different approaches to display the two graphs side by side.\n\nThe first one uses the package {**patchwork**}.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-fig-norm-dist-3 lst-cap=\"Display Figure 12-4 and 12-5\"}\nlibrary(patchwork)\np1 + p2\n```\n\n::: {.cell-output-display}\n![Normal Distributions with µ of 0; σ of 0.5 (left) and σ of 2 (right)](12-normal-distribution_files/figure-html/fig-norm-dist-3-1.png){#fig-norm-dist-3 width=8in height=4in}\n:::\n:::\n\n\n\nThe second approach uses the Quarto [figure panels](https://quarto.org/docs/authoring/figures.html) with `{layout-ncol=2}`\n\n::: {layout-ncol=2}\n\n::: {.cell}\n\n```{.r .cell-code}\np1\n```\n\n::: {.cell-output-display}\n![Normal Distribution μ = 0, σ = 0.5](12-normal-distribution_files/figure-html/fig-norm-p1-1.png){#fig-norm-p1 width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np2\n```\n\n::: {.cell-output-display}\n![Normal Distribution:μ = 0, σ = 2](12-normal-distribution_files/figure-html/fig-norm-p2-1.png){#fig-norm-p2 width=672}\n:::\n:::\n\n\n:::\n\n### Replicate Figure 12-6\n\n**Figure 12-6 (Book, p.108), here it is @fig-12-06.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-norm-dist-fuse lst-cap=\"Replicate Figure 12-6: Normal distribution with μ = 20.6 and σ = 1.62\"}\nggplot2::ggplot(data.frame(x = c(10, 30)), \n                ggplot2::aes(x = x)) +\n    ggplot2::stat_function(fun = function(x) dnorm(x, mean = 20.6, sd = 1.62)) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Normal distribution with μ = 20.6 and σ = 1.62\",\n        x = \"Value\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![A normal distribution with μ = 20.6 and σ = 1.62](12-normal-distribution_files/figure-html/fig-norm-dist-fuse-1.png){#fig-norm-dist-fuse fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 12-7\n\n**Figure 12-7 (Book, p.109), here it is @fig-12-07.**\n\nI am going to use two different approaches: The first one is the one I have used myself already several times in other occasions. See for instance [Plot intervals of defined boundaries](https://bookdown.org/pbaumgartner/sr2-notes/03-sampling-the-imaginary.html#plot-interval-of-defined-boundaries) in Statistical Rethinking 2nd edition.)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-norm-dist-area1 lst-cap=\"Area representing fuse length less than or equal to 18 seconds\"}\nfuse <- tibble::tibble(x = seq(0, 30, 0.01),\n                       y = dnorm(x, mean = 20.6, sd = 1.62))\n\nggplot2::ggplot(fuse, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_area(data = fuse |>  \n                       dplyr::filter(x >= 0 & x <= 18),\n                       fill = \"steelblue\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Replicate Figure 12-5 of this page:\n        Area representing fuse length less than or equal to 18 seconds\",\n        x = \"Value\",\n        y = \"Density\"\n    ) \n```\n\n::: {.cell-output-display}\n![The area under the curve that we’re interested in](12-normal-distribution_files/figure-html/fig-norm-dist-area1-1.png){#fig-norm-dist-area1 fig-align='center' width=70%}\n:::\n:::\n\n\nAt first I didn't succeed with the approach above because I used `data = fuse,` instead of `data = fuse |>`. I got a somewhat cryptical error message:\n\n> Error in UseMethod(\"filter\") : \n  no applicable method for 'filter' applied to an object of class \"logical\"\n\nAs I could not found the error I consulted the internet search and learned about another approach with `ggplot2::stat_function()` from the article \"Visualizing Sampling Distributions: Learn how to add areas under the curve in sampling distributions\" by [ggplot2tutor.com](https://ggplot2tutor.com/tutorials/sampling_distributions):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-norm-dist-area2 lst-cap=\"Area representing fuse length less than or equal to 18 seconds\"}\nggplot2::ggplot(data.frame(x = c(0, 30)), ggplot2::aes(x)) +\n  ggplot2::stat_function(fun = function(x) dnorm(x, mean = 20.6, sd = 1.62),\n                geom = \"line\",\n                xlim = c(0, 30)) +\n  ggplot2::stat_function(fun = function(x) dnorm(x, mean = 20.6, sd = 1.62),\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(0, 18)) +\n  ggplot2::xlim(0, 30) +\n  ggplot2::theme_bw() +\n  ggplot2::labs(\n        title = \"Replicate Figure 12-5 of this page:\n        Area representing fuse length less than or equal to 18 seconds\",\n        x = \"Value\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![The area under the curve that we’re interested in](12-normal-distribution_files/figure-html/fig-norm-dist-area2-1.png){#fig-norm-dist-area2 fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 12-8\n\n**Figure 12-8 (Book, p.111), here it is @fig-12-08.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-norm-dist-area68 lst-cap=\"Highlight sixty-eight percent of the probability density\"}\nggplot2::ggplot(data.frame(x = c(0, 30)), ggplot2::aes(x)) +\n  ggplot2::stat_function(fun = function(x) dnorm(x, mean = 20.6, sd = 1.62),\n                geom = \"line\",\n                xlim = c(0, 30)) +\n  ggplot2::stat_function(fun = function(x) dnorm(x, mean = 20.6, sd = 1.62),\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(20.6 - 1.62, 20.6 + 1.62)) +\n  ggplot2::xlim(0, 30) +\n  ggplot2::theme_bw() +\n  ggplot2::labs(\n        title = \"Replicate Figure 12-6 of this page:\n        Highlight sixty-eight percent of the probability density\",\n        x = \"Value\",\n        y = \"Density\"\n    ) +\n  ggplot2::annotate(geom = \"text\",\n           x = 20.5, y = .15,\n           label = \"68%\",\n           color = \"white\")\n```\n\n::: {.cell-output-display}\n![Sixty-eight percent of the probability density (area under the curve) lies between one standard deviation of the mean in either direction.](12-normal-distribution_files/figure-html/fig-norm-dist-area68-1.png){#fig-norm-dist-area68 fig-align='center' width=70%}\n:::\n:::\n\n\n### Replicate Figure 12-9\n\nComparing normal with beta distribution with the following example data:\n\n- **Data**: observing three values of 1 and four values of 0\n- **Beta**: $\\alpha = 3$ and $\\beta = 4$ \n- **Normal**: $n = 7$, $\\mu = \\frac{3}{7} = 0.43$, $\\sigma = sd(c(1,1,1,0,0,0,0)) = 0.53$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code #lst-fig-norm-beta lst-cap=\"Compare beta distribution with normal distribution\"}\nggplot2::ggplot(data.frame(x = c(1,1,1,0,0,0,0)), ggplot2::aes(x)) +\n  ggplot2::stat_function(fun = function(x) dnorm(x, mean(x), sd(x)),\n                geom = \"line\",\n                ggplot2::aes(color = \"Normal\"),\n                xlim = c(0, 1)) +\n  ggplot2::stat_function(fun = function(x) dbeta(x, 3, 4),\n                geom = \"line\",\n                ggplot2::aes(color = \"Beta\"),\n                xlim = c(0, 1)) +\n  ggplot2::theme_bw() +\n  ggplot2::scale_colour_manual(\"Distribution:\", values = c(\"red\", \"blue\")) +\n  ggplot2::theme(legend.position = \"top\") +\n  ggplot2::labs(\n        x = \"Probability\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![Comparing the beta distribution to the normal distribution](12-normal-distribution_files/figure-html/fig-norm-beta-1.png){#fig-norm-beta fig-align='center' width=70%}\n:::\n:::\n",
    "supporting": [
      "12-normal-distribution_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}